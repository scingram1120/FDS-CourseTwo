{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c64a342-fe4a-4d2d-8ab4-3db49e449855",
   "metadata": {},
   "source": [
    "# Machine Learning I Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376144d5-b17e-4f6e-b0ee-b889a8dcb808",
   "metadata": {},
   "source": [
    "### 1. (Fake) Titanic Data Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce16bd0-f868-4eff-bc24-97a8b4f9d307",
   "metadata": {},
   "source": [
    "The file 'titanicMachLearn.csv' contains (fake) data showing an SES (socioeconomic status) measure, fare paid for the ticket, and whether the person survived or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274bda5b-d8ec-4293-9ab7-c11e458b4a1a",
   "metadata": {},
   "source": [
    "**1a.** Do a k=3 nearest neighbor classification on the data using an 80/20 training/test split. Summarize the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef411a15-4d40-4b80-a652-dc57b28df154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression              # for simulating data\n",
    "from sklearn.model_selection import train_test_split      # splitting training and test data\n",
    "from sklearn.linear_model import LinearRegression         # making the linear predictor model\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # compute some diagnostics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('/Users/shannoningram/house/Livingroom/singram-258/FDS-CourseTwo/Data/titanicMachLearn.csv')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c201f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Convert titanic to data frame and split x and y\n",
    "titanic_df = pd.DataFrame(titanic)\n",
    "x = titanic[['SES', 'Fare']].to_numpy()\n",
    "\n",
    "y = titanic['Survived'].to_numpy()\n",
    "\n",
    "\n",
    "print(\"The shapes of the x and y variables: \",x.shape,y.shape)\n",
    "print()\n",
    "print(\"Scatter plot\")\n",
    "plt.scatter(x[:,0], x[:,1], c=y, alpha =.5)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "# Scatter plot of the test data showing the decision boundary\n",
    "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, cmap='viridis')\n",
    "\n",
    "# Create the decision boundary\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "XY = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = svm.decision_function(XY).reshape(XX.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], \n",
    "           alpha=0.5, linestyles=['--', '-', '--'])\n",
    "\n",
    "plt.title(\"Training Data with SVM Decision Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec67bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "print(acc_score)\n",
    "print(\"________\")\n",
    "print(conf_matrix)\n",
    "print(\"________\")\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05270efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def machine(a,b):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(a, b, test_size=0.2, random_state=42)\n",
    "    print(\"Train shape  Test Shape  Regular\")\n",
    "    print(X_train.shape,\"\", X_test.shape, \"\", X.shape)\n",
    "    print(y_train.shape,\"\", y_test.shape, \"\", y.shape)\n",
    "    model = LinearRegression() # too easy!\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    cls_report = classification_report(y_test, y_pred)\n",
    "    print(f\"Accuracy Score: {acc_score:.2f}%\")\n",
    "    print(conf_matrix)\n",
    "    print(cls_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5551a5f7-d2ec-4027-8411-df68e7bedff0",
   "metadata": {},
   "source": [
    "**1b.** Make a scatter plot of the data with color showing the survival status. Does the plot intuitivly agree with the performance of your classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e395a-039b-4013-a054-74e08ef80434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e37a7fb8-8437-4290-b109-ca57070e01d4",
   "metadata": {},
   "source": [
    "### 2. Iris Data Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f9e7f2-36c0-4bb9-a1d2-d53057a4a8a2",
   "metadata": {},
   "source": [
    "Do a nearest neighbors classification on the iris data using the 2 variables you think would work best based on the pair-pair plot we did in class (i.e. don't use the exact same variables we used in the in-class tutorial).\n",
    "\n",
    "Compare the results with the results we got in class using the first two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fef01-a4d8-4a71-b869-f4b04204eb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
